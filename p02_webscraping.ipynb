{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f4ee630",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# 1 - Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3c58d71",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-23T00:55:57.462443Z",
     "start_time": "2022-04-23T00:55:57.115678Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bts\n",
    "from datetime import datetime\n",
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "pd.set_option('display.float_format', '{:.2f}'.format)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd5457e",
   "metadata": {},
   "source": [
    "# 2 - Helper Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e46ba658",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## 2.1 - Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "edf6a8ec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-23T00:55:57.467367Z",
     "start_time": "2022-04-23T00:55:57.463675Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "###################################################################\n",
    "#                     Data Processing H&M\n",
    "###################################################################\n",
    "\n",
    "def dp_hm(path):\n",
    "    \n",
    "    data = pd.read_csv(path)\n",
    "    \n",
    "    \n",
    "    # Removendo dados duplicados\n",
    "    \n",
    "    data = data.drop_duplicates()\n",
    "    \n",
    "    \n",
    "    # Removendo dados nulos/faltantes das principais colunas\n",
    "    \n",
    "    data = data.dropna(subset=['product_id', 'product_name', 'product_price', 'product_composition', 'product_fit'])\n",
    "    data = data.reset_index(drop=True)\n",
    "    \n",
    "    \n",
    "    # Removendo dados fora de contexto das principais colunas\n",
    "    \n",
    "    data = data.loc[~((data['product_fit'] == \"\"\"The model is 189cm/6'2\" and wears a size 31/32\"\"\") |\n",
    "                     (data['product_fit'] == \"\"\"The model is 187cm/6'2\" and wears a size 31/32\"\"\")),:]\n",
    "    \n",
    "    \n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "625f3d21",
   "metadata": {},
   "source": [
    "## 2.2 - Regular expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b45ddf81",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-23T01:22:15.154005Z",
     "start_time": "2022-04-23T01:22:15.140935Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "###################################################################\n",
    "#                         Regex H&M\n",
    "###################################################################\n",
    "\n",
    "def regex_hm(data):\n",
    "    \n",
    "    # Extraindo informações da coluna 'product_composition'\n",
    "    \n",
    "    y = []\n",
    "    \n",
    "    regex = 'Shell:\\s(.+%)[A-Z]|Shell:\\s(.+%)'\n",
    "    regex2 = 'Composition([Cotton].+%)[A-Z]|%([Cotton].+%)'\n",
    "    regex3 = 'Composition([Cotton].+%)|%([Cotton].+%)'\n",
    "        \n",
    "    for i in range(len(data)):\n",
    "        \n",
    "        if \"Shell\" in data.loc[i, 'product_composition']:\n",
    "            if re.search(regex, data.loc[i, 'product_composition']).group(2) == None:\n",
    "                y.append(re.search(regex, data.loc[i, 'product_composition']).group(1))\n",
    "\n",
    "            else:\n",
    "                y.append(re.search(regex, data.loc[i, 'product_composition']).group(2))\n",
    "\n",
    "        elif \"Pocket\" in data.loc[i, 'product_composition']:\n",
    "            if re.search(regex2, data.loc[i, 'product_composition']).group(2) == None:\n",
    "                y.append(re.search(regex2, data.loc[i, 'product_composition']).group(1))\n",
    "\n",
    "            else:\n",
    "                y.append(re.search(regex2, data.loc[i, 'product_composition']).group(2))\n",
    "        \n",
    "        elif \"Lining\" in data.loc[i, 'product_composition']:\n",
    "            if re.search(regex2, data.loc[i, 'product_composition']).group(2) == None:\n",
    "                y.append(re.search(regex2, data.loc[i, 'product_composition']).group(1))\n",
    "\n",
    "            else:\n",
    "                y.append(re.search(regex2, data.loc[i, 'product_composition']).group(2))\n",
    "                \n",
    "        else:\n",
    "            if re.search(regex3, data.loc[i, 'product_composition']).group(2) == None:\n",
    "                y.append(re.search(regex3, data.loc[i, 'product_composition']).group(1))\n",
    "\n",
    "            else:\n",
    "                y.append(re.search(regex3, data.loc[i, 'product_composition']).group(2))\n",
    "        \n",
    "    data1 = pd.DataFrame([y]).T\n",
    "    data1.columns = ['product_composition']\n",
    "    data1 = data1['product_composition'].str.split(',', expand=True)\n",
    "    \n",
    "    data_ref = pd.DataFrame(index=np.arange(len(data)) ,columns=['cotton', 'spandex', 'polyester', 'elastomultiester'])\n",
    "    \n",
    "    df_cotton = data1[0]\n",
    "    df_cotton.name = 'cotton'\n",
    "    data_ref = pd.concat([data_ref, df_cotton], axis=1)\n",
    "    data_ref = data_ref.iloc[:, ~data_ref.columns.duplicated(keep='last')]\n",
    "    \n",
    "    \n",
    "    df_spandex = data1.loc[data1[1].str.contains('Spandex', na=True),1]\n",
    "    df_spandex.name = 'spandex'\n",
    "    df_spandex = df_spandex.combine_first(data1[2])\n",
    "    data_ref = pd.concat([data_ref, df_spandex], axis=1)\n",
    "    data_ref = data_ref.iloc[:, ~data_ref.columns.duplicated(keep='last')] \n",
    "    data_ref['spandex'] = data_ref['spandex'].fillna('Spandex 0%')\n",
    "\n",
    "    \n",
    "    df_polyester = data1.loc[data1[1].str.contains('Polyester', na=True),1]\n",
    "    df_polyester.name = 'polyester'\n",
    "    data_ref = pd.concat([data_ref, df_polyester], axis=1)\n",
    "    data_ref = data_ref.iloc[:, ~data_ref.columns.duplicated(keep='last')] \n",
    "    data_ref['polyester'] = data_ref['polyester'].fillna('Polyester 0%')\n",
    "\n",
    "    \n",
    "    df_elasto = data1.loc[data1[1].str.contains('Elastomultiester', na=True), 1]\n",
    "    df_elasto.name = 'elastomultiester'\n",
    "\n",
    "    data_ref = pd.concat([data_ref, df_elasto], axis=1)\n",
    "    data_ref = data_ref.iloc[:, ~data_ref.columns.duplicated(keep='last')] \n",
    "    data_ref['elastomultiester'] = data_ref['elastomultiester'].fillna('Elastomultiester 0%')\n",
    "    \n",
    "    \n",
    "    data = pd.concat([data, data_ref], axis=1)\n",
    "\n",
    "    data['cotton'] = data['cotton'].apply(lambda x: int(re.search('\\d+', x).group(0))/100)\n",
    "    data['spandex'] = data['spandex'].apply(lambda x: int(re.search('\\d+', x).group(0))/100)\n",
    "    data['polyester'] = data['polyester'].apply(lambda x: int(re.search('\\d+', x).group(0))/100)\n",
    "    data['elastomultiester'] = data['elastomultiester'].apply(lambda x: int(re.search('\\d+', x).group(0))/100)\n",
    "\n",
    "    \n",
    "    # Extraindo o preço das colunas 'product_price' e 'product_price_new'\n",
    "    \n",
    "    data['product_price'] = data['product_price'].apply(lambda x: re.search('\\w.+', x).group(0))\n",
    "    data['product_price_new'] = data['product_price_new'].apply(lambda x: re.search('\\w.+', x).group(0) if pd.notnull(x) else x)\n",
    "    \n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c364531",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e88b0b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bdba4a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d00a14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4bf8031",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f800fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a0db0e1f",
   "metadata": {},
   "source": [
    "# 3 - Web Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbeb21fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4394789d",
   "metadata": {},
   "source": [
    "# 4 - Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beed7f09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d93ac2c1",
   "metadata": {},
   "source": [
    "# 5 - Data Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195577b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "24258b78",
   "metadata": {},
   "source": [
    "# 6 - EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f97a164",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b261f41e",
   "metadata": {},
   "source": [
    "# 7 - Key Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ad30f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "34e8f241",
   "metadata": {},
   "source": [
    "# 8 - Conclusion and Next Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f76700",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebcc0c59",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
